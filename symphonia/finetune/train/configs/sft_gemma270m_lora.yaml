base_id: google/gemma-3-270m
peft:
  r: 16
  alpha: 32
  dropout: 0.05
  target_modules: [q_proj, k_proj, v_proj, o_proj]
quant:
  load_in_4bit: true
train:
  epochs: 1
  per_device_train_batch_size: 8
  gradient_accumulation_steps: 4
  lr: 2.0e-4
  warmup_ratio: 0.03
  max_seq_len: 1024
  packing: true
  seed: 1337
system:
  bf16: true
  gradient_checkpointing: true
  output_dir: runs/finetune/{exp}/checkpoints
data:
  train_path: runs/finetune/{exp}/train.parquet
  eval_path: runs/finetune/{exp}/val.parquet
